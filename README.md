Wikipedia Chatbot using LangChain, FastAPI, and OpenAI
Project Overview
This project is an AI-powered Wikipedia Chatbot that allows users to ask natural language questions and receive intelligent answers. The chatbot is built using LangChain for query orchestration, Pinecone as a vector database for semantic search, OpenAIâ€™s GPT model as the language model, FastAPI for backend integration, and Streamlit for an interactive UI.

Tech Stack & Workflow
1ï¸âƒ£ LangChain for Graph Orchestration

Handles the logic for processing user queries and retrieving relevant Wikipedia information.
Uses retrieval-augmented generation (RAG) to improve responses by combining vector search with LLM capabilities.
2ï¸âƒ£ Pinecone as the Vector Database

Stores Wikipedia embeddings for fast and efficient similarity search.
Enables semantic search to fetch relevant documents based on query meaning rather than exact words.
3ï¸âƒ£ OpenAI GPT for Answer Generation

Uses OpenAIâ€™s LLM to generate human-like responses based on the retrieved Wikipedia content.
Enhances answers by rephrasing and structuring the information for clarity.
4ï¸âƒ£ FastAPI for Backend Integration

Provides a lightweight, high-performance REST API to handle user queries.
Exposes a /wiki_search/ endpoint to process user questions and return intelligent responses.
5ï¸âƒ£ Streamlit for Chatbot UI

Creates an interactive chat-based UI where users can type questions and receive instant responses.
Maintains a conversation history for better user experience.
How It Works
ğŸ”¹ User enters a question in the chatbot UI.
ğŸ”¹ FastAPI sends the query to LangChain for processing.
ğŸ”¹ Pinecone searches for the most relevant Wikipedia passages.
ğŸ”¹ OpenAI LLM refines the response using the retrieved information.
ğŸ”¹ Streamlit displays the answer in an intuitive chat format.

Key Features
âœ… Fast & Accurate â€“ Combines vector search with LLM intelligence.
âœ… Conversational UI â€“ Uses Streamlit for an engaging chatbot experience.
âœ… Scalable Architecture â€“ Built with modular components (FastAPI, Pinecone, OpenAI, LangChain).
âœ… Real-time Responses â€“ Ensures low latency for quick query resolution.
